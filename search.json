[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Bibliographic Data Science",
    "section": "",
    "text": "Preface\nThis book is an attempt to implement the ideas described in the essay An outline of an imagined training course on bibliographic data science published in Bibliographic data blog, 2026.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Bibliographic data science is a relatively new interdisciplinary field of research that lies at the intersection of library science (or, more broadly, cultural heritage science), history and social sciences, and certain components of computer science. The objective of bibliographic data science is to establish previously hidden or possibly only suspected historical or collection trends based on data sources containing a (typically but not exclusively) large number of bibliographic records, ideally all those related to a given topic (e.g., national bibliographies), and on data science methods. Some of the field’s research questions:\n\nWhat was the spatial distribution and prosopography of 17th-century German legal dissertations? (Heßbrüggen-Walter 2025)\nWhat degree of interdisciplinarity can be observed based on the metadata of philosophical dissertations? (Heßbrüggen-Walter 2024)\nHow did the format and language of books change over time in different regions? (Lahti et al. 2019)\nWhat are the patterns of translations from a given language, how have they changed, and which languages were super-central, central, and peripheral in a given era?6\nWhat impact do publishers have on fiction?7\nWhat were the profiles of the various book collections?\nIs there a correlation between the genre and format of the book?8\nHow have genre proportions changed?9\nHow many early modern publications could have been destroyed without a trace?10\nHow can the reception of works be examined using bibliographic data?11\nWhat is the quality of cultural heritage data, and what improvement strategies can be developed?12\nHow do cultural heritage data, data structures, and standards help (or hinder) answering the above questions? What development opportunities does the research suggest for cultural heritage data standards?13\n\nAlthough digital humanities education has developed dynamically in recent years, computer-based analysis of bibliographic sources is unfortunately rarely featured, and similarly absent from library science and IT education. In my opinion, this gap could be remedied by a new informal vocational training program that would appeal to those who are interested in some of the above issues and who already have some knowledge in one of the relevant fields (e.g., library science, cultural history, literary sociology, information technology). The analysis of records based on library bibliographic standards would probably also be of interest in library training. The training may take the form of a summer university or a seminar/course jointly organized by several university departments. Participants in the training could be university students or practicing professionals.\n\n\n\n\nHeßbrüggen-Walter, Stefan. 2024. “Interdisciplinarity in the 17th Century? A Co-Occurrence Analysis of Early Modern German Dissertation Titles.” Synthese 203 (2): 67. https://doi.org/10.1007/s11229-024-04494-2.\n\n\n———. 2025. “Early Modern Dissertations in French Libraries: The EMDFL Dataset.” Journal of Open Humanities Data 11 (June): 36. https://doi.org/10.5334/johd.307.\n\n\nLahti, Leo, Jani Marjanen, Hege Roivainen, and Mikko Tolonen. 2019. “Bibliographic Data Science and the History of the Book (c. 1500–1800).” Cataloging & Classification Quarterly 57 (1): 5–23. https://doi.org/10.1080/01639374.2018.1543747.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "ch2a.html",
    "href": "ch2a.html",
    "title": "3  Scientific theories and models",
    "section": "",
    "text": "Darnton and his followers, Bourdieu, quantitative history, computational and data models of historical events – Thibodeau and Thaller",
    "crumbs": [
      "Theoretical models",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Scientific theories and models</span>"
    ]
  },
  {
    "objectID": "ch2b.html",
    "href": "ch2b.html",
    "title": "4  Cultural heritage data models",
    "section": "",
    "text": "the work-expression-manifestation-item model and its branches, ontologies, archival data models",
    "crumbs": [
      "Theoretical models",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cultural heritage data models</span>"
    ]
  },
  {
    "objectID": "ch3a.html",
    "href": "ch3a.html",
    "title": "5  data acquisition",
    "section": "",
    "text": "5.1 Creating directories\nabstract: Main types of bibliographic data and data sources (library catalogs, citation databases, research data repositories, historical sources). Methods of data acquisition (standards, application programming interfaces, and tools), information about data structure (metadata schemas and serialization formats), terms of use.\nDigital data can be retrieved in three main methods. The most convenient option is for these to be available as downloadable files (e.g., as reusable research data), however this type of data sharing is relatively rare. It is more common for data sources to be accessed through some kind of application programming interface. Various applications are available for the most common interfaces (OAI-PMH, Z39.50, SRW/SRU, SPARQL), so programming is not necessarily required, but time must be set aside to study the institution-specific settings and parameters of the interfaces. Finally, it is often the case that no previous opportunity was available. At this point, we extract the data from the HTML source of the website, assuming that the typographical formatting consistently indicates certain semantic elements17 – but in this case, it is worth consulting with the website operator to see if there are any other options not documented on the site. Whichever solution you choose, make sure that the data license allows reuse. After downloading the data, the first step is to import it. Programming libraries supporting various bibliographic formats are available; for MARC21, for example, there are ones for Java, Python, Go, JavaScript, R, PHP, and other programming languages. In this textbook we will work with Python, but the code could be adapted to other programming languages.\nThere are four main types of data sources for library history research:\nIn this textbook we will work with different directories:\nThe first programming task is to create these directories. To create them we use the os Python library that provides standard operating system functions, such as makedirs that creates a directory.\nThe code of this section is available at scripts/ch3a-create-directories.py of the repository.",
    "crumbs": [
      "The data analysis workflow",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>data acquisition</span>"
    ]
  },
  {
    "objectID": "ch3a.html#creating-directories",
    "href": "ch3a.html#creating-directories",
    "title": "5  data acquisition",
    "section": "",
    "text": "data: the data we created\nraw-data: our original data sources downloaded from data providers’ sites\nplots: the output of data visualization\n\n\n1import os\n\n2directories = ['data', 'raw-data', 'plots']\n\n3for directory in directories:\n4    if not os.path.exists(directory):\n5        os.makedirs(directory)\n\n1\n\nimport the os library\n\n2\n\ncreate a list with three strings, the names of the directories\n\n3\n\niterate of the directories one by one. In each iteration the name of the current directory will be stored in the variable directory\n\n4\n\ncheck if the directory does not exist. If it exists the script skips the directory and takes the next one. If it doesn’t exist, it continue with the next command\n\n5\n\ncreating the directory (due to the test in the previous line only if it doesn’t exist already)",
    "crumbs": [
      "The data analysis workflow",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>data acquisition</span>"
    ]
  },
  {
    "objectID": "ch3a.html#download-a-file",
    "href": "ch3a.html#download-a-file",
    "title": "5  data acquisition",
    "section": "5.2 Download a file",
    "text": "5.2 Download a file\nYou can find a list of downloadable library catalogues ḣere. Now download a relatively small file with MARC records of the Latvian National Bibliography (2014-2023) provided by the Open Data Portal of the National Library of Latvia. The files are compressed with zip, so in order to use them we should extract them, and because the zip file contains a data subdirectory, we rename that to lnb (after the domain name of the National Library of Latvia).\n1import urllib.request\nimport zipfile\nimport os\n\n2url = 'https://dati.lnb.lv/files/natl_bibliography-2014-2023-marc.zip'\ntarget_dir = 'raw-data'\ntarget_file = target_dir + '/lnb-natl_bibliography-2014-2023-marc.zip'\n\n3urllib.request.urlretrieve(url, target_file)\n\n4with zipfile.ZipFile(target_file, 'r') as zip_ref:\n    zip_ref.extractall(target_dir)\n\n5os.rename(target_dir + '/data', target_dir + '/lnb')\n\n1\n\nImport the Python libraries: urllib for the download, and zipfile for uncompressing\n\n2\n\ncreating variables\n\n3\n\ncall the download function with two arguments: the URL of the data source and the target file in our system\n\n4\n\nuncompress the zip file to our target directory\n\n5\n\nrename the data subdirectory (comes inside the zip file) to lnb\n\n\nAt the end of the process we will have a file raw-data/lnb/natl_bibliography-2014-2023-marc.xml, a set of MARC21 record in MARCXML serialization format, that is MARC21 in XML.\nThe code of this section is available at scripts/ch3a-download-a-file.py of the repository.",
    "crumbs": [
      "The data analysis workflow",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>data acquisition</span>"
    ]
  },
  {
    "objectID": "ch3b.html",
    "href": "ch3b.html",
    "title": "6  data validation",
    "section": "",
    "text": "Technical validity (XML, JSON validity check) and quality assessment.",
    "crumbs": [
      "The data analysis workflow",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>data validation</span>"
    ]
  },
  {
    "objectID": "ch3c.html",
    "href": "ch3c.html",
    "title": "7  preprocessing",
    "section": "",
    "text": "File formats, data structures, conversion, and data loss control.",
    "crumbs": [
      "The data analysis workflow",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>preprocessing</span>"
    ]
  },
  {
    "objectID": "ch3d.html",
    "href": "ch3d.html",
    "title": "8  data harmonisation",
    "section": "",
    "text": "normalization and data enrichment. The reproducible conversion into a data set suitable for quantitative humanities analysis.",
    "crumbs": [
      "The data analysis workflow",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>data harmonisation</span>"
    ]
  },
  {
    "objectID": "ch3e.html",
    "href": "ch3e.html",
    "title": "9  data analysis",
    "section": "",
    "text": "data analysis and data visualization with programming (Python, R) and specialized tools.",
    "crumbs": [
      "The data analysis workflow",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>data analysis</span>"
    ]
  },
  {
    "objectID": "ch3f.html",
    "href": "ch3f.html",
    "title": "10  dissemination",
    "section": "",
    "text": "dissemination of results. Publication of software and research data for reuse.",
    "crumbs": [
      "The data analysis workflow",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>dissemination</span>"
    ]
  },
  {
    "objectID": "ch4.html",
    "href": "ch4.html",
    "title": "11  After the research",
    "section": "",
    "text": "The broader context. Professional communities, conferences, journals, continuing education opportunities.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>After the research</span>"
    ]
  },
  {
    "objectID": "ap1.html",
    "href": "ap1.html",
    "title": "12  Books",
    "section": "",
    "text": "Just as there is no teaching material specifically focused on digital book history, there are no books on this subject either. Once again, we can only recommend books on related topics.\n\nGavin, Michael. 2023. Literary Mathematics: Quantitative Theory for Textual Studies. Stanford University Press. ISBN 978-1-5036-3282-0 (Stanford Text Technologies.)\nArnold, Taylor, and Lauren Tilton. 2015. Humanities Data in R: Exploring Networks, Geospatial Data, Images, and Text. Springer International Publishing. ISBN 978-3-319-20702-5 (Quantitative Methods in the Humanities and Social Sciences)\nBilbro, Rebecca, Tony Ojeda, and Benjamin Bengfort. 2018. Applied Text Analysis with Python. 1st edition. O’Reilly Media, Inc. ISBN 978-1-4919-6303-6\nGonzales, Brighid M. 2020. Systems Librarianship: A Practical Guide for Librarians. Bloomsbury Publishing. ISBN 979-8-8818-7951-8 (Practical Guides for Librarians)\nGooding, Paul, Melissa M. Terras, and Sarah Ames, eds. 2025. Library Catalogues as Data: Research, Practice and Usage. Facet Publishing. ISBN 978-1-78330-658-9\nKlinke, Harald. 2025. Cultural Data Science: An Introduction to R. Springer Nature Switzerland. ISBN 978-3-031-88130-5. (Quantitative Methods in the Humanities and Social Sciences)\nManovich, Lev. 2020. Cultural Analytics. The MIT Press. ISBN 978-0-262-03710-5\nKarsdorp, Folgert, Mike Kestemont, and Allen Riddell. 2021. Humanities Data Analysis: Case Studies with Python. Princeton University Press. ISBN 978-0-691-17236-1\nCrymble, Adam. 2021. Technology and the Historian: Transformations in the Digital Age. University of Illinois Press. ISBN 978-0-252-08569-7 (Topics in the Digital Humanities)\nJockers, Matthew L., and Rosamond Thalken. 2020. Text Analysis with R: For Students of Literature. Springer International Publishing. ISBN 978-3-030-39643-5 (Quantitative Methods in the Humanities and Social Sciences)\nNelson, Catherine. 2024. Software Engineering for Data Scientists: From Notebooks to Scalable Systems. O’Reilly. ISBN 978-1-0981-3620-8",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Books</span>"
    ]
  },
  {
    "objectID": "ap2.html",
    "href": "ap2.html",
    "title": "13  Journals",
    "section": "",
    "text": "The following journals regularly publish studies that are relevant for bibliographical data science:\n\nCode4Lib Journal\nComputational Humanities Research\nCurrent Research in Digital History\nDigital Humanities Quarterly\nDigital Scholarship in the Humanities\nInternational Journal of Digital Humanities\nInternational Journal of Humanities and Arts Computing\nJournal of Cultural Analytics\nJournal of Computing and Cultural Heritage\nJournal of Digital History\nJournal of Open Humanities Data\nOpen Library of Humanities Journal\nTransformations: A DARIAH Journal\nZeitschrift für digitale Geisteswissenschaften",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Journals</span>"
    ]
  },
  {
    "objectID": "ap3.html",
    "href": "ap3.html",
    "title": "14  Conferences",
    "section": "",
    "text": "The broader context. Professional communities, conferences, journals, continuing education opportunities.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Conferences</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Heßbrüggen-Walter, Stefan. 2024. “Interdisciplinarity in the 17th\nCentury? A Co-Occurrence Analysis of Early Modern\nGerman Dissertation Titles.” Synthese 203\n(2): 67. https://doi.org/10.1007/s11229-024-04494-2.\n\n\n———. 2025. “Early Modern Dissertations\nin French Libraries: The\nEMDFL Dataset.” Journal of Open\nHumanities Data 11 (June): 36. https://doi.org/10.5334/johd.307.\n\n\nLahti, Leo, Jani Marjanen, Hege Roivainen, and Mikko Tolonen. 2019.\n“Bibliographic Data Science and the\nHistory of the Book (c. 1500–1800).”\nCataloging & Classification Quarterly 57 (1): 5–23. https://doi.org/10.1080/01639374.2018.1543747.",
    "crumbs": [
      "References"
    ]
  }
]